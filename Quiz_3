
#install.packages("caret", dependencies = c("Depends", "Suggests"))

library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rattle)

### Q1 1. Subset the data to a training set and testing set based on the Case variable in the data set. 
# 2. Set the seed to 125. Fit a CART model with the rpart method using all predictor variables and default caret settings. 
# 3. In the final model what would be the final model prediction for cases with the following variable values:
#    a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 
#    b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100 
#    c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100 
#    d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2 

set.seed(125)
is.train <- which(segmentationOriginal$Case == 'Train')
train <- segmentationOriginal[is.train  , ]
test <- segmentationOriginal[-is.train  , ]

mod <- train(Class ~ . , method="rpart" , data=train)
mod$finalModel
# visual presentation of final model::
fancyRpartPlot(mod$finalModel)

# a == PS , b == WS , c == PS , d == cant tell since it doesn't hit first fraction

###  *************** Q1 Alternate Method ***********************

set.seed(125)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
options(scipen=999)

#1. Subset the data to a training set and testing set based on the Case variable in the data set. 
#2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings. 
#3. In the final model what would be the final model prediction for cases with the following variable values:
#  PS >> a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 
#  WS >>  b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100 
#  PS >>  c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100 
#  NULL  d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2 

training <- segmentationOriginal[which(segmentationOriginal$Case=='Train') , ]
testing <- segmentationOriginal[which(segmentationOriginal$Case=='Test') , ]
set.seed(125)

modFit <- train( Class ~ . , method = 'rpart' , data = training)

print(modFit$finalModel)

plot(modFit$finalModel , uniform = TRUE , main = 'Classification Tree')
text(modFit$finalModel , use.n = TRUE , all = TRUE , cex = 0.6)

fancyRpartPlot(modFit$finalModel)

* denotes terminal node

1) root 1009 373 PS (0.63032706 0.36967294)  
  2) TotalIntenCh2< 45323.5 454  34 PS (0.92511013 0.07488987) *
  3) TotalIntenCh2>=45323.5 555 216 WS (0.38918919 0.61081081)  
    6) FiberWidthCh1< 9.673245 154  47 PS (0.69480519 0.30519481) *
    7) FiberWidthCh1>=9.673245 401 109 WS (0.27182045 0.72817955) *

# -----------------------------------------------------

### Q2

# If K is small in a K-fold cross validation is the bias in the estimate of out-of-sample (test set) accuracy smaller or bigger? 
# If K is small is the variance in the estimate of out-of-sample (test set) accuracy smaller or bigger. 
# Is K large or small in leave one out cross validation?
# The bias is smaller and the variance is smaller. Under leave one out cross validation K is equal to the sample size.
# The bias is smaller and the variance is smaller. Under leave one out cross validation K is equal to one.
# The bias is larger and the variance is smaller. Under leave one out cross validation K is equal to the sample size.
# The bias is larger and the variance is smaller. Under leave one out cross validation K is equal to two.

### Question 3
# Load the olive oil data using the commands:
  
library(pgmm)
data(olive)
olive = olive[,-1]
# These data contain information on 572 different Italian olive oils from multiple regions in Italy. 
# Fit a classification tree where Area is the outcome variable. 
# Then predict the value of area for the following data frame using the tree command with all defaults
# What is the resulting prediction? Is the resulting prediction strange? 
# Why or why not?
olive_mod <-  train(Area ~ . , method="rpart" , data=olive)

newdata = as.data.frame(t(colMeans(olive)))

estimates <- predict(olive_mod , newdata = newdata)
estimates

### Answer >> 2.783. It is strange because Area should be a qualitative variable - but tree is reporting the average value of Area as a numeric variable in the leaf predicted for newdata

### Q4
# Load the South Africa Heart Disease Data and create training and test sets 
# Then set the seed to 13234 and fit a logistic regression model 
# (method="glm", be sure to specify family="binomial") with Coronary Heart Disease (chd) 
# as the outcome and age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol as predictors. 
# Calculate the misclassification rate for your model using this function and a prediction on the "response" scale:

# What is the misclassification rate on the training set? 
# What is the misclassification rate on the test set?

library(ElemStatLearn)
library(caret)
data(SAheart)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)

health_mod <- train(chd ~ age + alcohol + obesity + typea + ldl , data = trainSA , method="glm", family="binomial" )
train_Prediction <- predict(health_mod , newdata = trainSA)
test_Prediction <- predict(health_mod , newdata = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}

print( c('test misclassification=' , round(missClass(testSA$chd , test_Prediction) , digits = 3) ))
print( c('train misclassification=' , round(missClass(trainSA$chd , train_Prediction) , digits = 3) ))

### ********************** ALternate QUestion ****************
# Load the South Africa Heart Disease Data and create training and test sets with the following code:
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]

# Then set the seed to 13234 
# fit a logistic regression model (method="glm", be sure to specify family="binomial") 
# with Coronary Heart Disease (chd) as the outcome and 
# age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, 
# and low density lipoprotein cholesterol as predictors. 
# Calculate the misclassification rate for your model using this function and a prediction on the "response" scale:

set.seed(13234)

train_model_glm <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl , data = trainSA , method = 'glm' , family="binomial")
prediction_train <- predict(train_model_glm , newdata =trainSA )
prediction_test <- predict(train_model_glm , newdata =testSA)

missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd , prediction_train)
missClass(testSA$chd , prediction_test)


# What is the misclassification rate on the training set? 
# What is the misclassification rate on the test set?

> missClass(trainSA$chd , prediction_train)
[1] 0.2727273
> missClass(testSA$chd , prediction_test)
[1] 0.3116883

### Q5
# Set the variable y to be a factor variable in both the training and test set. 
# Then set the seed to 33833. Fit a random forest predictor relating the factor variable y to the remaining variables. 
# Read about variable importance in random forests here: http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr 
# The caret package uses by defualt the Gini importance. 
# Calculate the variable importance using the varImp function in the caret package. What is the order of variable importance?
#Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train))
data(vowel.test) 
set.seed(33833)
vowel.test

vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)

mod_train <- train( y~. , data = vowel.train , method = 'rf' , importance=TRUE)

final_mod_train <- mod_train$finalModel

varImp(final_mod_train)
importance(final_mod_train)

******** Q5 Alternative **********

# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test) 

# Set the variable y to be a factor variable in both the training and test set. 
# Then set the seed to 33833. 
# Fit a random forest predictor relating the factor variable y to the remaining variables. 
# Read about variable importance in random forests here: http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr 
# The caret package uses by defualt the Gini importance. 
# Calculate the variable importance using the varImp function in the caret package. 
# What is the order of variable importance?


vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)

set.seed(33833)
v_train.cf <- train(y ~ ., data = vowel.train , methof = 'rf')
varImp(v_train.cf)

   Overall
x.2  100.000
x.1   98.834
x.5   38.651
x.6   25.628
x.8   19.065
x.4    8.397
x.9    5.417
x.3    4.728
x.7    1.252
x.10   0.000
> 

